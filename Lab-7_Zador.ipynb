{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №7. \"Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../data/DataSet3-v8.csv\")\n",
    "\n",
    "# удаление пропусков\n",
    "df['engine_capacity']=df['engine_capacity'].fillna(0)\n",
    "# удаление дублей\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "# перевод категориал. данных в бинар.\n",
    "bn = BinaryEncoder()\n",
    "df_bn_obj = bn.fit_transform(df.select_dtypes(include=['object','bool'])).astype('int8')\n",
    "df_num = df.select_dtypes(exclude=['object', 'bool'])\n",
    "df = pd.concat([df_num, pd.DataFrame(df_bn_obj)], axis=1)\n",
    "# EDA\n",
    "outlier = df[['odometer_value', 'year_produced', 'engine_capacity', 'price_usd', 'number_of_photos', 'up_counter', 'duration_listed']]\n",
    "Q1 = outlier.quantile(0.25)\n",
    "Q3 = outlier.quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "df_filtered = outlier[~((outlier < (Q1 - 1.5 * IQR)) |(outlier > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "index_list = list(df_filtered.index.values)\n",
    "df_filtered = df[df.index.isin(index_list)]\n",
    "\n",
    "df_reg = df_filtered\n",
    "\n",
    "# Разбиение на тренеровочную и тестовую выборки\n",
    "y_reg = pd.DataFrame(df_reg[\"price_usd\"])\n",
    "x_reg = pd.DataFrame(df_reg.drop([\"price_usd\"], axis=1))\n",
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_reg, y_reg, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"../data/weatherAUS.csv\")\n",
    "\n",
    "# Удаление пропусков\n",
    "data.dropna(inplace=True,ignore_index=True)\n",
    "# Перевод категориал. данных в бинарные\n",
    "f = lambda x : str(x)[5:7]\n",
    "data['Date'] = data['Date'].transform(f).astype(int)\n",
    "\n",
    "data['RainToday'] = data['RainToday'].replace(\"Yes\", 1)\n",
    "data['RainToday'] = data['RainToday'].replace(\"No\", 0)\n",
    "data['RainTomorrow'] = data['RainTomorrow'].replace(\"Yes\", 1)\n",
    "data['RainTomorrow'] = data['RainTomorrow'].replace(\"No\", 0)\n",
    "\n",
    "bn = BinaryEncoder()\n",
    "data_category = bn.fit_transform(data.select_dtypes(include=['object'])).astype(int)\n",
    "data_num = data.select_dtypes(exclude=['object'])\n",
    "data = pd.concat([data_num, pd.DataFrame(data_category)], axis=1)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Балансировка данных\n",
    "df_0 = data.loc[data['RainTomorrow']==0]\n",
    "df_0 = df_0.sample(len(data.loc[data['RainTomorrow']==1]))\n",
    "df_conc = pd.concat([data.loc[data['RainTomorrow']==1], df_0])\n",
    "\n",
    "df_class = df_conc\n",
    "\n",
    "# Разбиение на тренеровочную и тестовую выборки\n",
    "x_class=pd.DataFrame(df_class.drop(['RainTomorrow'],axis=1))\n",
    "y_class=pd.DataFrame(df_class['RainTomorrow'])\n",
    "x_train_c, x_test_c, y_train_c, y_test_c = train_test_split(x_class, y_class, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решение задач"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем полносвязную нейронную сеть для решения задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем модель, как набор последовательных слоев\n",
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_dim = x_reg.shape[1]),\n",
    "        # на втором скрытом слое будет 32 нейрона\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # на выходе один нейрон, функция активации не применяется\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 64)                3776      \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6401 (25.00 KB)\n",
      "Trainable params: 6401 (25.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 5s 4ms/step - loss: 30818760.0000\n",
      "Epoch 2/30\n",
      "731/731 [==============================] - 3s 4ms/step - loss: 16922610.0000\n",
      "Epoch 3/30\n",
      "731/731 [==============================] - 3s 4ms/step - loss: 15614375.0000\n",
      "Epoch 4/30\n",
      "731/731 [==============================] - 3s 4ms/step - loss: 15373330.0000\n",
      "Epoch 5/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 15320528.0000\n",
      "Epoch 6/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 15021489.0000\n",
      "Epoch 7/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 14881907.0000\n",
      "Epoch 8/30\n",
      "731/731 [==============================] - 5s 7ms/step - loss: 14419724.0000\n",
      "Epoch 9/30\n",
      "731/731 [==============================] - 5s 7ms/step - loss: 14469698.0000\n",
      "Epoch 10/30\n",
      "731/731 [==============================] - 4s 6ms/step - loss: 14108047.0000\n",
      "Epoch 11/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 13753631.0000\n",
      "Epoch 12/30\n",
      "731/731 [==============================] - 3s 5ms/step - loss: 13384701.0000\n",
      "Epoch 13/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 13011999.0000\n",
      "Epoch 14/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 12969828.0000\n",
      "Epoch 15/30\n",
      "731/731 [==============================] - 3s 4ms/step - loss: 12485226.0000\n",
      "Epoch 16/30\n",
      "731/731 [==============================] - 4s 6ms/step - loss: 11929650.0000\n",
      "Epoch 17/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 11164408.0000\n",
      "Epoch 18/30\n",
      "731/731 [==============================] - 3s 5ms/step - loss: 11097393.0000\n",
      "Epoch 19/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 10516197.0000\n",
      "Epoch 20/30\n",
      "731/731 [==============================] - 3s 5ms/step - loss: 10057767.0000\n",
      "Epoch 21/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 10048929.0000\n",
      "Epoch 22/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 9513732.0000\n",
      "Epoch 23/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 9942290.0000\n",
      "Epoch 24/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 9628457.0000\n",
      "Epoch 25/30\n",
      "731/731 [==============================] - 3s 5ms/step - loss: 9626669.0000\n",
      "Epoch 26/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 9520070.0000\n",
      "Epoch 27/30\n",
      "731/731 [==============================] - 3s 5ms/step - loss: 8892845.0000\n",
      "Epoch 28/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 9242111.0000\n",
      "Epoch 29/30\n",
      "731/731 [==============================] - 3s 5ms/step - loss: 9027805.0000\n",
      "Epoch 30/30\n",
      "731/731 [==============================] - 4s 5ms/step - loss: 9724879.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a16d7ec2b0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
    "model_regression.fit(x_train_r, y_train_r, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183/183 [==============================] - 1s 3ms/step\n",
      "2019.353705805473\n",
      "183/183 [==============================] - 1s 3ms/step\n",
      "7939571.380427819\n"
     ]
    }
   ],
   "source": [
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_test_r, model_regression.predict(x_test_r)))\n",
    "print(mean_squared_error(y_test_r, model_regression.predict(x_test_r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"Нейронная сеть для решения задачи классификации будет очень похожа на ту сеть для регрессии, однако у нее по другому будет организован выходной слой. У нас есть 2 стратегии наполнения выходного слоя нейронами:<br><br>- при решении задачи бинарной классификации мы можем расположить на выходном слое один нейрон с функцией активации sigmoid (значения от 0 и 1), после чего округлять полученные значения; значение нейрона покажет уверенность сети в предсказании; также мы можем расположить 2 нейрона на выходном слое и применить функцию softmax. Тогда сумма значений нейронов выходного слоя будет 1, а предсказание мы сможем получить определив нейрон с наибольшим значением;<br>- в случае многоклассовой классификации, как правило, на выходном слое располагаются k нейронов (по количеству классов), функция активации - softmax; нейрон с наибольшим значением определяет предсказанный класс.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас задача бинарной классификации, попробуем обе стратегии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "521/521 [==============================] - 5s 5ms/step - loss: 1.1585\n",
      "Epoch 2/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.5575\n",
      "Epoch 3/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.4996\n",
      "Epoch 4/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.4848\n",
      "Epoch 5/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.4776\n",
      "Epoch 6/10\n",
      "521/521 [==============================] - 3s 5ms/step - loss: 0.4722\n",
      "Epoch 7/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.4705\n",
      "Epoch 8/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.4629\n",
      "Epoch 9/10\n",
      "521/521 [==============================] - 3s 5ms/step - loss: 0.4726\n",
      "Epoch 10/10\n",
      "521/521 [==============================] - 3s 6ms/step - loss: 0.4621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a10cb06f40>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_dim = x_class.shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # сначала используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(x_train_c, y_train_c, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18271753],\n",
       "       [0.39443824],\n",
       "       [0.86982596],\n",
       "       ...,\n",
       "       [0.84257776],\n",
       "       [0.37973768],\n",
       "       [0.7084429 ]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# предсказание сети\n",
    "model_classification_1.predict(x_test_c, verbose=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Округлим полученные значения и выведем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79      4125\n",
      "           1       0.79      0.79      0.79      4077\n",
      "\n",
      "    accuracy                           0.79      8202\n",
      "   macro avg       0.79      0.79      0.79      8202\n",
      "weighted avg       0.79      0.79      0.79      8202\n",
      "\n",
      "[[3260  865]\n",
      " [ 853 3224]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.around(model_classification_1.predict(x_test_c, verbose=None))\n",
    "print(classification_report(y_test_c, y_pred))\n",
    "print(confusion_matrix(y_test_c, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы у меня сбалансированы не идеально, поэтому попробую взвесить функцию потерь. Задам весам величины обратные количеству элементов классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 1 / y_train_c[y_train_c==0].shape[0]\n",
    "w1 = 1 / y_train_c[y_train_c==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      4125\n",
      "           1       0.75      0.84      0.79      4077\n",
      "\n",
      "    accuracy                           0.78      8202\n",
      "   macro avg       0.78      0.78      0.78      8202\n",
      "weighted avg       0.78      0.78      0.78      8202\n",
      "\n",
      "[[2987 1138]\n",
      " [ 662 3415]]\n"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_dim = x_class.shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(x_train_c, y_train_c, epochs=5, verbose=None, class_weight={0: w0, 1: w1})\n",
    "model_classification_1.predict(x_test_c, verbose=None)\n",
    "\n",
    "y_pred = np.around(model_classification_1.predict(x_test_c, verbose=None))\n",
    "print(classification_report(y_test_c, y_pred))\n",
    "print(confusion_matrix(y_test_c, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не сказать, что стало лучше, но попробовать я попробовала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробую разместить 2 нейрона на выходном слое и использовать softmax в качестве функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1a10e88cc70>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_dim = x_class.shape[1]),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
    "model_classification_2.fit(x_train_c, y_train_c, epochs=10, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8336381 , 0.16636191],\n",
       "       [0.5292172 , 0.47078276],\n",
       "       [0.15808822, 0.8419118 ],\n",
       "       ...,\n",
       "       [0.1617107 , 0.83828926],\n",
       "       [0.4361903 , 0.56380963],\n",
       "       [0.29720974, 0.70279026]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2.predict(x_test_c, verbose=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое значение можно интерпретировать как вероятность отнесения объекта к соответствующему классу (0 или 1). Воспользуемся функцией argmax для того, чтобы получить итоговые предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получим индексы максимального значения для каждого элемента\n",
    "y_pred = [np.argmax(pred) for pred in model_classification_2.predict(x_test_c, verbose=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.69      0.76      4125\n",
      "           1       0.74      0.88      0.80      4077\n",
      "\n",
      "    accuracy                           0.78      8202\n",
      "   macro avg       0.79      0.78      0.78      8202\n",
      "weighted avg       0.80      0.78      0.78      8202\n",
      "\n",
      "[[2834 1291]\n",
      " [ 485 3592]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_c, y_pred))\n",
    "print(confusion_matrix(y_test_c, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_regression.save('../models/RegressionModel')\n",
    "model_classification_1.save('../models/ClassificationModel1')\n",
    "model_classification_2.save('../models/ClassificationModel2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, learning_rate, epoch_count, layers, training_data, y, alfa):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch_count = epoch_count\n",
    "        self.layers = layers \n",
    "        layers_count = len(layers)\n",
    "        self.training_data =  np.asarray(training_data)\n",
    "        self.target_output = y\n",
    "        self.alfa = alfa\n",
    "        training_count = len(x[:,0])\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1.0/(1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_deriv(x):\n",
    "        return sigmoid(x) * (1 - sigmoid(x))\n",
    "    \n",
    "    def relu(x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def relu_deriv(x):\n",
    "        return (x>=0).astype(float)\n",
    "    \n",
    "    def softmax(x):\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    def sparse_cross_entropy(z, y):\n",
    "        return -np.log(np.array([z[j, y[j]]] for j in range(len(y))))\n",
    "\n",
    "    def to_full_batch(y, num_classes):\n",
    "        y_full = np.zeros(len(y),num_classes)\n",
    "        for j, yj in enumerate(y):\n",
    "            y_full[j, yj] = 1\n",
    "        return\n",
    "\n",
    "    def fit():\n",
    "        w = []\n",
    "        t = []\n",
    "        dwi = []\n",
    "        dbi = []\n",
    "        hi = self.training_data\n",
    "        h=[hi]\n",
    "        for i in range(0,self.layers_count-2,3):\n",
    "            Wi = np.random.randn(self.layers[i], self.layers[i+3])\n",
    "            bi = np.random.randn(1, self.layers[i+3])\n",
    "            ti = hi.dot(Wi + bi)\n",
    "            if func_act == \"relu\": \n",
    "                hi = relu(ti)\n",
    "            elif func_act == \"sigmoid\":\n",
    "                hi = sigmoid(ti)\n",
    "            elif func_act == \"tanh\":\n",
    "                hi = tanh(ti)\n",
    "            h.append(hi)\n",
    "            w.append(Wi)\n",
    "            t.append(ti)\n",
    "        z = softmax(ti)\n",
    "        E = sparse_cross_entropy(z, self.target_output)\n",
    "\n",
    "        y_full = to_full_batch(self.target_output, self.layers[self.layers_count-1])\n",
    "        dE_dti = z - y_full\n",
    "        dti.append(dE_dti)\n",
    "        for i in reversed(range(2,self.layers_count-2,3)):\n",
    "            dE_dWi = h[i-1].T.dot(dE_dti)\n",
    "            dE_dbi = dE_dti\n",
    "            # j = i-1\n",
    "            dE_dhj = dE_dti.dot(w[i-1])\n",
    "            dE_dti = dE_dhj * relu_deriv()\n",
    "        dE_dW1 = self.training_data.T.dot(dE_dt1)\n",
    "\n",
    "\n",
    "\n",
    "    learning_rate = 1   \n",
    "\n",
    "    input_dim = 3\n",
    "    hidden_dim = 4\n",
    "    \n",
    "\n",
    "    epoch_count = 1\n",
    "\n",
    "    weights_ItoH = np.random.randn(input_dim, hidden_dim)\n",
    "    weights_HtoO = np.random.randn(1, H_dim)\n",
    "\n",
    "    preActivation_H = np.zeros(H_dim)\n",
    "    postActivation_H = np.zeros(H_dim)\n",
    "\n",
    "    #forward\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for @: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m las \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m      9\u001b[0m kas \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m],[\u001b[38;5;241m2\u001b[39m],[\u001b[38;5;241m3\u001b[39m]]\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkas\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for @: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "#training_data = np.asarray(training_data)\n",
    "#training_count = len(training_data[:,0])\n",
    "mas = [\n",
    "    1, \"relu\", 60,\n",
    "    2, \"relu\", 15,\n",
    "    3, \"tanh\", 32\n",
    "]\n",
    "las = [1, 2, 3]\n",
    "kas = [[1],[2],[3]]\n",
    "print(las @ kas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
